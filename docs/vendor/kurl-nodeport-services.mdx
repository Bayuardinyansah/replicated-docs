import PortsApplicationURL from "../partials/custom-resource-application/_ports-applicationURL.mdx"
import NginxKotsApp from "../partials/application-links/_nginx-kots-app.mdx"
import NginxK8sApp from "../partials/application-links/_nginx-k8s-app.mdx"
import NginxService from "../partials/application-links/_nginx-service.mdx"
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import NginxDeployment from "../partials/application-links/_nginx-deployment.mdx"
import LinkToService from "../partials/application-links/_link-to-service.mdx"

# Exposing Services Using NodePorts

This topic describes how to create a NodePort service for exposing services in Replicated Embedded Cluster or Replicated kURL installations. 

For information about exposing services in existing cluster installations through the Replicated KOTS port forward tunnel, see [Port Forwarding Services with KOTS](/vendor/admin-console-port-forward).

## Overview

Unlike installations into existing clusters, KOTS does _not_ automatically open the port forward tunnel for installations in embedded clusters provisioned on virtual machines (VMs) or bare metal servers. This is because it cannot be verified that the ports are secure and authenticated.

To expose the Admin Console in installations with [Embedded Cluster](/vendor/embedded-overview) or [kURL](/vendor/kurl-about), KOTS creates the Admin Console as a NodePort service so it can be accessed at the node's IP address on port 8800. Additionally, for kURL installations, the UIs of Prometheus, Grafana, and Alertmanager are also exposed using NodePorts.

For each application service that you want to expose for Embedded Cluster or kURL installations, Replicated recommends that you configure a NodePort type service to allow users to access the service from their local machine outside the cluster.

## Create a NodePort Service

Services with `type: NodePort` are able to be contacted from outside the cluster by connecting to any node using the appropriate protocol and port. This is helpful for installations on VMs or bare metal servers where users must be able access your application from their local machine rather than from inside the cluster. For more information about working with the NodePort service type, see [type: NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport) in the Kubernetes documentation.

To expose a service in kURL or Embedded Cluster installations, the service must be included in your release as a NodePort. After creating a NodePort type service, you can then add a link to the service on the Admin Console dashboard where it can be accessed by users after the application is installed. For more information, see [Add a Link to a NodePort Service from the Admin Console](#add-link) below.

The following shows an example of a NodePort type service:

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: sentry
    labels:
      app: sentry
  spec:
    type: NodePort
    ports:
    - port: 9000
      targetPort: 9000
      nodePort: 9000
      protocol: TCP
      name: sentry
    selector:
      app: sentry
      role: web
  ```

### Use KOTS Annotations to Conditionally Deploy NodePort Services 

You can use the KOTS [`kots.io/when`](/vendor/packaging-include-resources#kotsiowhen) annotation to conditionally deploy a service. This is useful when you want to deploy a ClusterIP or LoadBalancer service for existing cluster installations, and deploy a NodePort service for Embedded Cluster or kURL installations. For more information, see [Conditionally Including or Excluding Resources](/vendor/packaging-include-resources).

To conditionally deploy a service based on the installation method, you can use the following KOTS template functions in the `kots.io/when` annotation:
* [IsKurl](/reference/template-functions-static-context#iskurl): Detects kURL installations. For example, `repl{{ IsKurl }}` returns true for kURL installations, and `repl{{ not IsKurl }}` returns true for non-kURL installations.
* [Distribution](/reference/template-functions-static-context#distribution): Returns the distribution of the cluster where KOTS is running. For example, `repl{{ eq Distribution "embedded-cluster" }}` returns true for Embedded Cluster installations and `repl{{ ne Distribution "embedded-cluster" }}` returns true for non-Embedded Cluster installations.

For example, the following `sentry` service with `type: NodePort` includes `annotation.kots.io/when: repl{{ eq Distribution "embedded-cluster" }}`. This creates a NodePort service _only_ when installing with Embedded Cluster:

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: sentry
    labels:
      app: sentry
  annotations:
  # This annotation prevents the NodePort service 
  # from being created in non-Embedded Cluster clusters
    kots.io/when: repl{{ eq Distribution "embedded-cluster" }}
  spec:
    type: NodePort
    ports:
    - port: 9000
      targetPort: 9000
      nodePort: 9000
      protocol: TCP
      name: sentry
    selector:
      app: sentry
      role: web
  ```

Similarly, to ensure that a `sentry` service with `type: ClusterIP` is only created in existing cluster installations, add `annotations.kots.io/when: repl{{ ne Distribution "embedded-cluster" }}` to the ClusterIP specification:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: sentry
  labels:
    app: sentry
annotations:
  # This annotation prevents the ClusterIP service 
  # from being created in Embedded Cluster installations
  kots.io/when: repl{{ ne Distribution "embedded-cluster" }}
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
    protocol: TCP
    name: sentry
  selector:
    app: sentry
    role: web
```

## Add a Link to a NodePort Service from the Admin Console {#add-link}

Configure the Kubernetes SIG Application and KOTS Application custom resources to add a link to a NodePort service from the Admin Console dashboard. This allows users to access the service after the application is installed.

For example:

![Admin Console dashboard with Open App link](/images/gitea-open-app.png)

[View a larger version of this image](/images/gitea-open-app.png)

For more information about adding links to the Admin Console dashboard using the Kubernetes SIG Application custom resource, see [Adding Links to the Dashboard](/vendor/admin-console-adding-buttons-links).

<LinkToService/>

### About Accessing the Service from the Admin Console

:::note
To be able to access the service, the firewall for the VM where the user installed must allow HTTP traffic and allow inbound traffic to the port where the service is exposed from their workstation. Users can consult their cloud provider's documentation for more information about updating firewall rules.
:::

During installations with Embedded Cluster or kURL, the Admin Console is automatically created and exposed on port 8800 on the node. In most cases, the user can navigate to the Admin Console URL provided in the output of the installation command at `vm-ip-address:8800` from their local workstation.

If the user is not able to access the Admin Console from this URL (for example, if the VM firewall does not allow inbound traffic to 8800), then they can access the Admin Console by forwarding a port on their local machine to the target port on the remote VM using the SSH client. For information about how to forward a port on a local machine to the Admin Console port 8800 on a remote VM, see [Accessing the Admin Console](/enterprise/installing-existing-cluster-automation#optional-access-the-admin-console) in _Installing with the CLI_.  

### Example: NGINX Application with ClusterIP and NodePort Services

The following example demonstrates how to expose a basic NGINX service for both existing cluster and kURL installations, including adding a link to the service on the Admin Console dashboard.

To test this example:

1. Add the `example-service.yaml`, `example-deployment.yaml`, `kots-app.yaml`, and `k8s-app.yaml` files provided below to a new, empty release in the Vendor Portal. Promote to the channel that you use for internal testing. For more information, see [Managing Releases with the Vendor Portal](releases-creating-releases).

    <Tabs>
    <TabItem value="service" label="example-service.yaml" default>
    <h5>Description</h5>
    <p>The YAML below contains ClusterIP and NodePort specifications for a service named <code>nginx</code>. Each specification uses the <code>kots.io/when</code> annotation with the Replicated IsKurl template function to conditionally include the service based on the installation type (existing cluster or embedded kURL cluster). For more information, see <a href="/vendor/packaging-include-resources">Conditionally Including or Excluding Resources</a> and <a href="/reference/template-functions-static-context#iskurl">IsKurl</a>.</p>
    <p>As shown below, both the ClusterIP and NodePort <code>nginx</code> services are exposed on port 80.</p>
    <h5>YAML</h5>
    <NginxService/>
    </TabItem>
    <TabItem value="deployment" label="example-deployment.yaml" default>
    <h5>Description</h5>
    <p>A basic Deployment specification for the NGINX application.</p>
    <h5>YAML</h5>
    <NginxDeployment/>
    </TabItem>
    <TabItem value="kots-app" label="kots-app.yaml" default>
    <h5>Description</h5>
    <p>The KOTS Application custom resource below adds port 80 to the KOTS port forward tunnel and maps port 8888 on the local machine. The specification also includes <code>applicationUrl: "http://nginx"</code> so that a link to the service can be added to the Admin Console dashboard.</p>
    <h5>YAML</h5>
    <NginxKotsApp/>
    </TabItem>
    <TabItem value="k8s-app" label="k8s-app.yaml" default>
    <h5>Description</h5>
    <p>Using the value of <code>ports.applicationUrl</code> in <code>kots-app.yaml</code>, the Kubernetes Application custom resource below adds a link to the port-forwarded service from the Admin Console dashboard. The label to be used for the link in the Admin Console is "Open App".</p>
    <h5>YAML</h5>
    <NginxK8sApp/>
    </TabItem>
    </Tabs>

1. Install the release into an existing cluster and confirm that the service was port-forwarded successfully by clicking **Open App** on the Admin Console dashboard. For more information, see [Online Installation in Existing Clusters](/enterprise/installing-existing-cluster).

1. If there is not already a Kubernetes installer promoted to the channel, add a Kubernetes installer to the release to support embedded cluster installs. For more information, see [Creating a Kubernetes Installer](/vendor/packaging-embedded-kubernetes).

1. Install the release into an embedded cluster on a VM and confirm that the service was exposed successfully by clicking **Open App** on the Admin Console dashboard. For more information, see [Online Installation with kURL](/enterprise/installing-kurl).

    :::note
    Ensure that the VM where you install allows HTTP traffic.
    :::