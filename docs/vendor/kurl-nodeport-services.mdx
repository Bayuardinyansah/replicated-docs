import PortsApplicationURL from "../partials/custom-resource-application/_ports-applicationURL.mdx"
import NginxKotsApp from "../partials/application-links/_nginx-kots-app.mdx"
import NginxK8sApp from "../partials/application-links/_nginx-k8s-app.mdx"
import NginxService from "../partials/application-links/_nginx-service.mdx"
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import NginxDeployment from "../partials/application-links/_nginx-deployment.mdx"
import LinkToService from "../partials/application-links/_link-to-service.mdx"

# Exposing Services Using NodePorts

This topic describes how to create a NodePort service for exposing services in [Replicated Embedded Cluster](/vendor/embedded-overview) or [Replicated kURL](/vendor/kurl-about) installations. 

For information about exposing services in existing cluster installations through the Replicated KOTS port forward tunnel, see [Port Forwarding Services with KOTS](/vendor/admin-console-port-forward).

## Overview

Unlike installations into existing clusters, KOTS does _not_ automatically open the port forward tunnel for installations in embedded clusters provisioned on virtual machines (VMs) or bare metal servers. This is because it cannot be verified that the ports are secure and authenticated.

To expose the Admin Console in installations with [Embedded Cluster](/vendor/embedded-overview) or [kURL](/vendor/kurl-about), KOTS creates the Admin Console as a NodePort service so it can be accessed at the node's IP address on port 8800. Additionally, for kURL installations, the UIs of Prometheus, Grafana, and Alertmanager are also exposed using NodePorts.

For each application service that you want to expose for Embedded Cluster or kURL installations, Replicated recommends that you configure a NodePort type service to allow users to access the service from their local machine outside the cluster.

## Create a NodePort Service

To expose a service in Embedded Cluster or kURL installations, the service must be included in your release as a NodePort. 

Services with `type: NodePort` are able to be contacted from outside the cluster by connecting to any node using the appropriate protocol and port. This is helpful for installations on VMs or bare metal servers where users must be able access your application from their local machine rather than from inside the cluster. For more information about working with the NodePort service type, see [type: NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport) in the Kubernetes documentation.

After creating a NodePort type service, you can add a link to the service on the Admin Console dashboard where it can be accessed by users after the application is installed. For more information, see [Add a Link to a NodePort Service from the Admin Console](#add-link) below.

The following shows an example of a NodePort type service:

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: sentry
    labels:
      app: sentry
  spec:
    type: NodePort
    ports:
    - port: 9000
      targetPort: 9000
      nodePort: 9000
      protocol: TCP
      name: sentry
    selector:
      app: sentry
      role: web
  ```

### Use KOTS Annotations to Conditionally Deploy NodePort Services 

You can use the KOTS [`kots.io/when`](/vendor/packaging-include-resources#kotsiowhen) annotation to conditionally deploy a service. This is useful when you want to deploy a ClusterIP or LoadBalancer service for existing cluster installations, and deploy a NodePort service for Embedded Cluster or kURL installations.

To conditionally deploy a service based on the installation method, you can use the following KOTS template functions in the `kots.io/when` annotation:
* [IsKurl](/reference/template-functions-static-context#iskurl): Detects kURL installations. For example, `repl{{ IsKurl }}` returns true for kURL installations, and `repl{{ not IsKurl }}` returns true for non-kURL installations.
* [Distribution](/reference/template-functions-static-context#distribution): Returns the distribution of the cluster where KOTS is running. For example, `repl{{ eq Distribution "embedded-cluster" }}` returns true for Embedded Cluster installations and `repl{{ ne Distribution "embedded-cluster" }}` returns true for non-Embedded Cluster installations.

For example, the following `sentry` service with `type: NodePort` includes `annotation.kots.io/when: repl{{ eq Distribution "embedded-cluster" }}`. This creates a NodePort service _only_ when installing with Embedded Cluster:

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: sentry
    labels:
      app: sentry
  annotations:
  # This annotation prevents the NodePort service 
  # from being created in non-Embedded Cluster clusters
    kots.io/when: repl{{ eq Distribution "embedded-cluster" }}
  spec:
    type: NodePort
    ports:
    - port: 9000
      targetPort: 9000
      nodePort: 9000
      protocol: TCP
      name: sentry
    selector:
      app: sentry
      role: web
  ```

Similarly, to ensure that a `sentry` service with `type: ClusterIP` is only created in existing cluster installations, add `annotations.kots.io/when: repl{{ ne Distribution "embedded-cluster" }}` to the ClusterIP specification:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: sentry
  labels:
    app: sentry
annotations:
  # This annotation prevents the ClusterIP service 
  # from being created in Embedded Cluster installations
  kots.io/when: repl{{ ne Distribution "embedded-cluster" }}
spec:
  type: ClusterIP
  ports:
  - port: 9000
    targetPort: 9000
    protocol: TCP
    name: sentry
  selector:
    app: sentry
    role: web
```

## About Accessing NodePort Services

After installation, you can allow users to access NodePort services by adding a link to the service on the Admin Console dashboard. Additional configuration is required to add a link to the dashboard.

### VM Firewall Requirements

To be able to access the Admin Console and the NodePort service, the firewall for the VM where the user installs must allow HTTP traffic and allow inbound traffic to the port where the service is exposed from their workstation. Users can consult their cloud provider's documentation for more information about updating firewall rules.

### Linking to User-Supplied or Static Hostnames

If the user will supply the hostname during installation, or if the hostname is known, you can add the URL to a Kubernetes SIG Application custom resource in your release to link to the NodePort service.

### Linking to Dynamic Hostnames Using KOTS

If the user does not supply a hostname during installation or if the hostname is dynamic, then you can use KOTS to rewrite the URL at the time of installation. This requires configuring both the Kubernetes SIG Application custom resource and the KOTS Application custom resource `ports` key.

#### Example: NGINX Application with ClusterIP and NodePort Services

The following example demonstrates how to expose a basic NGINX service for both existing cluster and kURL installations, including adding a link to the service on the Admin Console dashboard.

To test this example:

1. Add the `example-service.yaml`, `example-deployment.yaml`, `kots-app.yaml`, and `k8s-app.yaml` files provided below to a new, empty release in the Vendor Portal. Promote to the channel that you use for internal testing. For more information, see [Managing Releases with the Vendor Portal](releases-creating-releases).

    <Tabs>
    <TabItem value="service" label="example-service.yaml" default>
    <h5>Description</h5>
    <p>The YAML below contains ClusterIP and NodePort specifications for a service named <code>nginx</code>. Each specification uses the <code>kots.io/when</code> annotation with the Replicated IsKurl template function to conditionally include the service based on the installation type (existing cluster or embedded kURL cluster). For more information, see <a href="/vendor/packaging-include-resources">Conditionally Including or Excluding Resources</a> and <a href="/reference/template-functions-static-context#iskurl">IsKurl</a>.</p>
    <p>As shown below, both the ClusterIP and NodePort <code>nginx</code> services are exposed on port 80.</p>
    <h5>YAML</h5>
    <NginxService/>
    </TabItem>
    <TabItem value="deployment" label="example-deployment.yaml" default>
    <h5>Description</h5>
    <p>A basic Deployment specification for the NGINX application.</p>
    <h5>YAML</h5>
    <NginxDeployment/>
    </TabItem>
    <TabItem value="kots-app" label="kots-app.yaml" default>
    <h5>Description</h5>
    <p>The KOTS Application custom resource below adds port 80 to the KOTS port forward tunnel and maps port 8888 on the local machine. The specification also includes <code>applicationUrl: "http://nginx"</code> so that a link to the service can be added to the Admin Console dashboard.</p>
    <h5>YAML</h5>
    <NginxKotsApp/>
    </TabItem>
    <TabItem value="k8s-app" label="k8s-app.yaml" default>
    <h5>Description</h5>
    <p>Using the value of <code>ports.applicationUrl</code> in <code>kots-app.yaml</code>, the Kubernetes Application custom resource below adds a link to the port-forwarded service from the Admin Console dashboard. The label to be used for the link in the Admin Console is "Open App".</p>
    <h5>YAML</h5>
    <NginxK8sApp/>
    </TabItem>
    </Tabs>

1. Install the release into an existing cluster and confirm that the service was port-forwarded successfully by clicking **Open App** on the Admin Console dashboard. For more information, see [Online Installation in Existing Clusters](/enterprise/installing-existing-cluster).

1. If there is not already a kURL installer promoted to the channel, add a kURL installer to the release to support kURL installs. For more information, see [Creating a kURL Installer](/vendor/packaging-embedded-kubernetes).

1. Install the release on a VM and confirm that the service was exposed successfully. To test the port forward, click **Open App** on the Admin Console dashboard after the application reaches a Ready state. For more information, see [Online Installation with kURL](/enterprise/installing-kurl).

    :::note
    Ensure that the VM where you install allows HTTP traffic.
    :::